#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
BERT ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
- ë¬¸ë§¥ì  ìœ ì‚¬ë„ ê³„ì‚°
- í‚¤ì›Œë“œ ë§¤ì¹­
- í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.bert_nlp import BertNLP
from services.database import PostgreSQLDatabase
from datetime import datetime
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict
import logging
from typing import List, Dict, Tuple, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class BertRecommendationSystem:
    """
    BERT ê¸°ë°˜ í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        """BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.bert_nlp = BertNLP()
        self.db = PostgreSQLDatabase()
        logger.info("BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def recommend_books_by_context(self, news_data: dict) -> Dict[str, List[Tuple[str, float]]]:
        """
        ë¬¸ë§¥ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ
        
        Args:
            news_data: ë‰´ìŠ¤ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ ë„ì„œ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ğŸ§  ë¬¸ë§¥ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ì‹œì‘")
        
        # ëª¨ë“  ë„ì„œ ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        query = """
            SELECT books_isbn, books_title, books_description 
            FROM tb_books 
            WHERE books_description IS NOT NULL AND books_description != ''
        """
        books = self.db.fetch_query(query)
        
        book_data = {
            'isbn': [book[0] for book in books],
            'title': [book[1] for book in books],
            'description': [book[2] for book in books]
        }
        
        recommendations = {}
        
        for category, keywords in news_data.items():
            logger.info(f"ğŸ“° {category} ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì¤‘...")
            
            category_recommendations = []
            
            for keyword in keywords:
                # í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë¬¸ë§¥ ìƒì„±
                context = f"{category} ê´€ë ¨ {keyword}ì— ëŒ€í•œ ë‚´ìš©"
                
                # ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
                similarities = self._calculate_contextual_similarities(
                    context, book_data['description']
                )
                
                # ìƒìœ„ ì¶”ì²œ ë„ì„œ ì„ íƒ
                top_books = self._get_top_recommendations(
                    similarities, book_data['isbn'], book_data['title'], 
                    threshold=0.3, top_k=5
                )
                
                category_recommendations.extend(top_books)
            
            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            recommendations[category] = self._merge_recommendations(category_recommendations)
        
        return recommendations
    
    def recommend_books_by_keywords(self, news_data: dict) -> Dict[str, List[Tuple[str, float]]]:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ
        
        Args:
            news_data: ë‰´ìŠ¤ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            
        Returns:
            í‚¤ì›Œë“œë³„ ì¶”ì²œ ë„ì„œ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ì‹œì‘")
        
        # ëª¨ë“  ë„ì„œ ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        query = """
            SELECT books_isbn, books_title, books_description 
            FROM tb_books 
            WHERE books_description IS NOT NULL AND books_description != ''
        """
        books = self.db.fetch_query(query)
        
        recommendations = defaultdict(list)
        
        for category, keywords in news_data.items():
            for keyword in keywords:
                # í‚¤ì›Œë“œ ì¶”ì¶œ
                keyword_tokens = self.bert_nlp.extract_keywords(keyword, top_k=5)
                
                for isbn, title, description in books:
                    if description:
                        # ë„ì„œ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                        book_keywords = self.bert_nlp.extract_keywords(description, top_k=10)
                        
                        # í‚¤ì›Œë“œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
                        keyword_similarity = 0
                        for kw1 in keyword_tokens:
                            for kw2 in book_keywords:
                                similarity = self.bert_nlp.calculate_word_similarity(kw1, kw2)
                                keyword_similarity = max(keyword_similarity, similarity)
                        
                        if keyword_similarity > 0.4:  # í‚¤ì›Œë“œ ìœ ì‚¬ë„ ì„ê³„ê°’
                            recommendations[keyword].append((isbn, keyword_similarity))
        
        # ê²°ê³¼ ì •ë¦¬
        final_recommendations = {}
        for keyword, recs in recommendations.items():
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_recs = sorted(recs, key=lambda x: x[1], reverse=True)
            final_recommendations[keyword] = sorted_recs[:5]
        
        return final_recommendations
    
    def recommend_books_by_clustering(self, news_data: dict, n_clusters: int = 5) -> Dict[str, List[Tuple[str, float]]]:
        """
        í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ
        
        Args:
            news_data: ë‰´ìŠ¤ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            n_clusters: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
            
        Returns:
            í´ëŸ¬ìŠ¤í„°ë³„ ì¶”ì²œ ë„ì„œ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ì‹œì‘")
        
        # ëª¨ë“  ë„ì„œ ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        query = """
            SELECT books_isbn, books_title, books_description 
            FROM tb_books 
            WHERE books_description IS NOT NULL AND books_description != ''
        """
        books = self.db.fetch_query(query)
        
        descriptions = [desc for _, _, desc in books if desc]
        isbns = [isbn for isbn, _, desc in books if desc]
        titles = [title for _, title, desc in books if desc]
        
        # ë„ì„œ ì„¤ëª… í´ëŸ¬ìŠ¤í„°ë§
        clusters = self.bert_nlp.cluster_texts(descriptions, n_clusters)
        
        recommendations = {}
        
        for category, keywords in news_data.items():
            for keyword in keywords:
                # í‚¤ì›Œë“œê°€ ì†í•  ê°€ì¥ ì í•©í•œ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
                best_cluster = self._find_best_cluster(keyword, clusters, descriptions)
                
                if best_cluster is not None:
                    # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ë„ì„œë“¤ ì¶”ì²œ
                    cluster_books = clusters[best_cluster]
                    
                    for book_idx in cluster_books:
                        if book_idx < len(isbns):
                            isbn = isbns[book_idx]
                            # í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì ìˆ˜ (0.6ìœ¼ë¡œ ê³ ì •)
                            recommendations.setdefault(keyword, []).append((isbn, 0.6))
        
        # ê²°ê³¼ ì •ë¦¬
        final_recommendations = {}
        for keyword, recs in recommendations.items():
            # ì¤‘ë³µ ì œê±°
            unique_recs = {}
            for isbn, score in recs:
                if isbn not in unique_recs or score > unique_recs[isbn]:
                    unique_recs[isbn] = score
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_recs = sorted(unique_recs.items(), key=lambda x: x[1], reverse=True)
            final_recommendations[keyword] = sorted_recs[:5]
        
        return final_recommendations
    
    def hybrid_recommendation(self, news_data: dict) -> Dict[str, List[Tuple[str, float]]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ (ë¬¸ë§¥ + í‚¤ì›Œë“œ + í´ëŸ¬ìŠ¤í„°ë§)
        
        Args:
            news_data: ë‰´ìŠ¤ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            
        Returns:
            í†µí•© ì¶”ì²œ ê²°ê³¼
        """
        logger.info("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œì‘")
        
        # ê° ë°©ë²•ë³„ ì¶”ì²œ ê²°ê³¼
        context_recs = self.recommend_books_by_context(news_data)
        keyword_recs = self.recommend_books_by_keywords(news_data)
        cluster_recs = self.recommend_books_by_clustering(news_data)
        
        # ê²°ê³¼ í†µí•©
        hybrid_recs = defaultdict(dict)
        
        # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = set()
        for recs in [context_recs, keyword_recs, cluster_recs]:
            all_keywords.update(recs.keys())
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ í†µí•© ì ìˆ˜ ê³„ì‚°
        for keyword in all_keywords:
            keyword_scores = {}
            
            # ë¬¸ë§¥ ê¸°ë°˜ ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.5)
            if keyword in context_recs:
                for isbn, score in context_recs[keyword]:
                    keyword_scores[isbn] = keyword_scores.get(isbn, 0) + score * 0.5
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.3)
            if keyword in keyword_recs:
                for isbn, score in keyword_recs[keyword]:
                    keyword_scores[isbn] = keyword_scores.get(isbn, 0) + score * 0.3
            
            # í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.2)
            if keyword in cluster_recs:
                for isbn, score in cluster_recs[keyword]:
                    keyword_scores[isbn] = keyword_scores.get(isbn, 0) + score * 0.2
            
            # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
            sorted_scores = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)
            hybrid_recs[keyword] = sorted_scores[:5]
        
        return dict(hybrid_recs)
    
    def save_recommendations_to_db(self, recommendations: Dict[str, List[Tuple[str, float]]], 
                                 method: str = "hybrid"):
        """
        ì¶”ì²œ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        
        Args:
            recommendations: ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            method: ì¶”ì²œ ë°©ë²•
        """
        logger.info(f"ğŸ’¾ ì¶”ì²œ ê²°ê³¼ DB ì €ì¥ ì‹œì‘ (ë°©ë²•: {method})")
        
        try:
            # ê¸°ì¡´ ì¶”ì²œ ë°ì´í„° ì‚­ì œ (ê°™ì€ ë°©ë²•ìœ¼ë¡œ ìƒì„±ëœ ê²ƒë“¤)
            delete_query = "DELETE FROM tb_recommend WHERE method = %s"
            self.db.execute_query(delete_query, (method,))
            
            # ìƒˆë¡œìš´ ì¶”ì²œ ë°ì´í„° ì‚½ì…
            insert_query = """
                INSERT IGNORE INTO tb_recommend 
                (news_keyword, books_isbn, similarity_score, method, created_at) 
                VALUES (%s, %s, %s, %s, NOW())
            """
            
            insert_count = 0
            for keyword, recs in recommendations.items():
                for isbn, score in recs:
                    self.db.execute_query(insert_query, (keyword, isbn, score, method))
                    insert_count += 1
            
            logger.info(f"âœ… ì¶”ì²œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {insert_count}ê°œ ë ˆì½”ë“œ")
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ì²œ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _calculate_contextual_similarities(self, context: str, descriptions: List[str]) -> List[float]:
        """ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        similarities = []
        for description in descriptions:
            if description:
                similarity = self.bert_nlp.calculate_contextual_similarity(context, description)
                similarities.append(similarity)
            else:
                similarities.append(0.0)
        return similarities
    
    def _get_top_recommendations(self, similarities: List[float], isbns: List[str], 
                               titles: List[str], threshold: float = 0.3, 
                               top_k: int = 5) -> List[Tuple[str, float, str]]:
        """ìƒìœ„ ì¶”ì²œ ë„ì„œ ì„ íƒ"""
        recommendations = []
        
        for i, similarity in enumerate(similarities):
            if similarity >= threshold and i < len(isbns):
                recommendations.append((isbns[i], similarity, titles[i]))
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        recommendations.sort(key=lambda x: x[1], reverse=True)
        
        return recommendations[:top_k]
    
    def _merge_recommendations(self, recommendations: List[Tuple[str, float, str]]) -> List[Tuple[str, float]]:
        """ì¶”ì²œ ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°"""
        merged = {}
        
        for isbn, score, title in recommendations:
            if isbn not in merged or score > merged[isbn]:
                merged[isbn] = score
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_recs = sorted(merged.items(), key=lambda x: x[1], reverse=True)
        
        return sorted_recs[:5]  # ìƒìœ„ 10ê°œ ë°˜í™˜
    
    def _find_best_cluster(self, keyword: str, clusters: Dict[int, List[int]], 
                          descriptions: List[str]) -> Optional[int]:
        """í‚¤ì›Œë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°"""
        best_cluster = None
        best_similarity = 0.0
        
        for cluster_id, book_indices in clusters.items():
            cluster_similarity = 0.0
            
            for book_idx in book_indices:
                if book_idx < len(descriptions):
                    description = descriptions[book_idx]
                    if description:
                        similarity = self.bert_nlp.calculate_contextual_similarity(keyword, description)
                        cluster_similarity += similarity
            
            # í´ëŸ¬ìŠ¤í„° í‰ê·  ìœ ì‚¬ë„
            if book_indices:
                cluster_similarity /= len(book_indices)
                
                if cluster_similarity > best_similarity:
                    best_similarity = cluster_similarity
                    best_cluster = cluster_id
        
        return best_cluster
    
    def evaluate_recommendation_quality(self, method: str = "hybrid"):
        """ì¶”ì²œ í’ˆì§ˆ í‰ê°€"""
        logger.info(f"ğŸ“ˆ ì¶”ì²œ í’ˆì§ˆ í‰ê°€ ì‹œì‘ (ë°©ë²•: {method})")
        
        try:
            # ì¶”ì²œ ë°ì´í„° ì¡°íšŒ
            query = """
                SELECT news_keyword, books_isbn, similarity_score 
                FROM tb_recommend 
                WHERE method = %s 
                ORDER BY similarity_score DESC
            """
            recommendations = self.db.fetch_query(query, (method,))
            
            if not recommendations:
                logger.warning(f"í‰ê°€í•  ì¶”ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {method}")
                return
            
            # í†µê³„ ê³„ì‚°
            scores = [score for _, _, score in recommendations]
            
            stats = {
                'total_recommendations': len(recommendations),
                'average_score': np.mean(scores),
                'max_score': np.max(scores),
                'min_score': np.min(scores),
                'std_score': np.std(scores),
                'high_quality_count': len([s for s in scores if s >= 0.7]),
                'medium_quality_count': len([s for s in scores if 0.4 <= s < 0.7]),
                'low_quality_count': len([s for s in scores if s < 0.4])
            }
            
            logger.info(f"ğŸ“Š ì¶”ì²œ í’ˆì§ˆ í‰ê°€ ê²°ê³¼ ({method}):")
            logger.info(f"  - ì´ ì¶”ì²œ ìˆ˜: {stats['total_recommendations']}")
            logger.info(f"  - í‰ê·  ì ìˆ˜: {stats['average_score']:.3f}")
            logger.info(f"  - ìµœê³  ì ìˆ˜: {stats['max_score']:.3f}")
            logger.info(f"  - ìµœì € ì ìˆ˜: {stats['min_score']:.3f}")
            logger.info(f"  - ê³ í’ˆì§ˆ ì¶”ì²œ: {stats['high_quality_count']}ê°œ")
            logger.info(f"  - ì¤‘í’ˆì§ˆ ì¶”ì²œ: {stats['medium_quality_count']}ê°œ")
            logger.info(f"  - ì €í’ˆì§ˆ ì¶”ì²œ: {stats['low_quality_count']}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ì²œ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.db.close()
        logger.info("BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì¢…ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ BERT ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")
    
    try:
        # í¬ë¡¤ëŸ¬ë¡œ ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        from services.crowling import Crowling
        crawler = Crowling()
        
        # ë‰´ìŠ¤ ì œëª© ê°€ì ¸ì˜¤ê¸° (BERT ì‹œìŠ¤í…œìš©)
        logger.info("ğŸ“¡ ì¤‘ì•™ì¼ë³´ ë‰´ìŠ¤ ì œëª© í¬ë¡¤ë§ ì¤‘...")
        news_titles = crawler.get_news_titles()
        logger.info(f"âœ… ë‰´ìŠ¤ ì œëª© í¬ë¡¤ë§ ì™„ë£Œ: {len(news_titles)}ê°œ ì¹´í…Œê³ ë¦¬")
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì œëª© ìˆ˜ ì¶œë ¥
        for category, titles in news_titles.items():
            logger.info(f"  - {category}: {len(titles)}ê°œ ì œëª©")
        
        # BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        recommender = BertRecommendationSystem()
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹¤í–‰ (ë‰´ìŠ¤ ì œëª© ì‚¬ìš©)
        logger.info("ğŸ”„ BERT ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œì‘...")
        recommendations = recommender.hybrid_recommendation(news_titles)
        
        # ê²°ê³¼ ì¶œë ¥
        total_recommendations = 0
        for category, recs in recommendations.items():
            logger.info(f"\nğŸ“š {category} ì¹´í…Œê³ ë¦¬ ì¶”ì²œ ë„ì„œ:")
            for isbn, score in recs[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
                logger.info(f"   - {isbn}: {score:.4f}")
            total_recommendations += len(recs)
        
        logger.info(f"\nğŸ“Š ì´ ì¶”ì²œ ìˆ˜: {total_recommendations}ê°œ")
        
        # DBì— ì €ì¥
        recommender.save_recommendations_to_db(recommendations, "hybrid")
        
        # í’ˆì§ˆ í‰ê°€
        recommender.evaluate_recommendation_quality("hybrid")
        
    except Exception as e:
        logger.error(f"âŒ BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        if 'recommender' in locals():
            recommender.close()

if __name__ == "__main__":
    main() 
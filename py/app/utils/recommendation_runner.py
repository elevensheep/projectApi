from services.crowling import Crowling
from services.database import MySQLDatabase
from services.nlp import Nlp
from datetime import datetime
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict

def recommend_books_by_keywords_enhanced(news_data: dict):
    """í–¥ìƒëœ í‚¤ì›Œë“œ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ"""
    db = MySQLDatabase()
    nlp = Nlp()
    today = datetime.now().strftime("%Y-%m-%d")

    # ëª¨ë¸ ë¡œë“œ
    nlp.LoadModel()
    
    print("ğŸ” í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘...")

    for category, keywords in news_data.items():
        print(f"ğŸ“° ì¹´í…Œê³ ë¦¬ '{category}' ì²˜ë¦¬ ì¤‘...")
        
        for keyword in keywords:
            # ë‰´ìŠ¤ í‚¤ì›Œë“œ ì €ì¥
            insert_news_sql = """
                INSERT INTO tb_news_keyword (news_category, news_date, news_keyword)
                VALUES (%s, %s, %s)
            """
            db.execute_query(insert_news_sql, (category, today, keyword))

            # 1. ì§ì ‘ ë§¤ì¹­ (ê¸°ì¡´ ë°©ì‹)
            direct_matches = find_direct_matches(db, keyword)
            
            # 2. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (ìƒˆë¡œìš´ ë°©ì‹)
            similarity_matches = find_similarity_matches(nlp, db, keyword)
            
            # 3. í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ë§¤ì¹­
            cluster_matches = find_cluster_matches(nlp, db, keyword, category)
            
            # ê²°ê³¼ í†µí•© ë° ê°€ì¤‘ì¹˜ ì ìš©
            all_matches = combine_matches(direct_matches, similarity_matches, cluster_matches)
            
            # ìµœì‹  news_id ê°€ì ¸ì˜¤ê¸°
            news_id_sql = """
                SELECT news_id FROM tb_news_keyword 
                WHERE news_category = %s AND news_date = %s AND news_keyword = %s
                ORDER BY news_id DESC LIMIT 1
            """
            news_id = db.fetch_query(news_id_sql, (category, today, keyword))[0][0]

            # ì¶”ì²œ ì €ì¥ (ê°€ì¤‘ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬)
            for isbn, score in all_matches:
                insert_recommend_sql = """
                    INSERT IGNORE INTO tb_recommend (news_id, books_isbn, similarity_score) 
                    VALUES (%s, %s, %s)
                """
                db.execute_query(insert_recommend_sql, (news_id, isbn, score))
                
    db.close()
    print("âœ… í–¥ìƒëœ ì¶”ì²œ ì™„ë£Œ ë° DB ì €ì¥ ì™„ë£Œ")

def find_direct_matches(db, keyword):
    """ì§ì ‘ ë§¤ì¹­ (ê¸°ì¡´ ë°©ì‹)"""
    book_sql = """
        SELECT books_isbn FROM tb_books 
        WHERE books_title LIKE %s OR books_description LIKE %s
    """
    matched_books = db.fetch_query(book_sql, (f'%{keyword}%', f'%{keyword}%'))
    return [(isbn[0], 1.0) for isbn in matched_books]  # ì§ì ‘ ë§¤ì¹­ì€ ìµœê³  ì ìˆ˜

def find_similarity_matches(nlp, db, keyword, top_k=10):
    """ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­"""
    if nlp.model is None:
        return []
    
    # ëª¨ë“  ì±…ì˜ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    query = """
        SELECT books_isbn, books_description 
        FROM tb_books 
        WHERE books_description IS NOT NULL AND books_description != ''
    """
    books = db.fetch_query(query)
    
    similarities = []
    for isbn, description in books:
        if not description:
            continue
            
        # ì±… ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        book_keywords = nlp.extract_nouns_enhanced([description])
        
        if not book_keywords:
            continue
        
        # í‚¤ì›Œë“œì™€ ì±… í‚¤ì›Œë“œ ê°„ì˜ ìµœëŒ€ ìœ ì‚¬ë„ ê³„ì‚°
        max_similarity = 0
        for book_keyword in book_keywords:
            try:
                if keyword in nlp.model.wv and book_keyword in nlp.model.wv:
                    similarity = nlp.model.wv.similarity(keyword, book_keyword)
                    max_similarity = max(max_similarity, similarity)
            except:
                continue
        
        if max_similarity > 0.3:  # ì„ê³„ê°’ ì„¤ì •
            similarities.append((isbn, max_similarity))
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ kê°œ ë°˜í™˜
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_k]

def find_cluster_matches(nlp, db, keyword, category, top_k=5):
    """í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ë§¤ì¹­"""
    if nlp.model is None:
        return []
    
    # ì¹´í…Œê³ ë¦¬ë³„ í´ëŸ¬ìŠ¤í„° ì •ë³´ (ë¯¸ë¦¬ ì •ì˜ëœ í´ëŸ¬ìŠ¤í„°)
    category_clusters = {
        'economy': ['ê²½ì œ', 'ê¸ˆìœµ', 'íˆ¬ì', 'ì£¼ì‹', 'ì€í–‰', 'ê¸°ì—…', 'ì‹œì¥'],
        'politics': ['ì •ì¹˜', 'ì •ë¶€', 'êµ­íšŒ', 'ëŒ€í†µë ¹', 'ì •ì±…', 'ë²•ì•ˆ', 'ì„ ê±°'],
        'society': ['ì‚¬íšŒ', 'êµìœ¡', 'ë³µì§€', 'í™˜ê²½', 'êµí†µ', 'ì•ˆì „', 'ê±´ê°•'],
        'sports': ['ìŠ¤í¬ì¸ ', 'ì¶•êµ¬', 'ì•¼êµ¬', 'ë†êµ¬', 'ì˜¬ë¦¼í”½', 'ì„ ìˆ˜', 'ê²½ê¸°'],
        'world': ['êµ­ì œ', 'ì™¸êµ', 'ë¬´ì—­', 'ì „ìŸ', 'í‰í™”', 'í˜‘ë ¥', 'ê°ˆë“±']
    }
    
    # ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” í´ëŸ¬ìŠ¤í„° í‚¤ì›Œë“œë“¤
    cluster_keywords = category_clusters.get(category.lower(), [])
    
    if not cluster_keywords:
        return []
    
    # í‚¤ì›Œë“œì™€ í´ëŸ¬ìŠ¤í„° í‚¤ì›Œë“œë“¤ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    cluster_similarities = []
    for cluster_keyword in cluster_keywords:
        try:
            if keyword in nlp.model.wv and cluster_keyword in nlp.model.wv:
                similarity = nlp.model.wv.similarity(keyword, cluster_keyword)
                cluster_similarities.append(similarity)
        except:
            continue
    
    if not cluster_similarities:
        return []
    
    # í´ëŸ¬ìŠ¤í„° ìœ ì‚¬ë„ì˜ í‰ê· 
    avg_cluster_similarity = np.mean(cluster_similarities)
    
    # í´ëŸ¬ìŠ¤í„°ì™€ ìœ ì‚¬í•œ ì±…ë“¤ ì°¾ê¸°
    query = """
        SELECT books_isbn, books_description 
        FROM tb_books 
        WHERE books_description IS NOT NULL AND books_description != ''
    """
    books = db.fetch_query(query)
    
    cluster_matches = []
    for isbn, description in books:
        if not description:
            continue
            
        book_keywords = nlp.extract_nouns_enhanced([description])
        
        if not book_keywords:
            continue
        
        # ì±… í‚¤ì›Œë“œì™€ í´ëŸ¬ìŠ¤í„° í‚¤ì›Œë“œ ê°„ì˜ ìœ ì‚¬ë„
        book_cluster_similarities = []
        for book_keyword in book_keywords:
            for cluster_keyword in cluster_keywords:
                try:
                    if book_keyword in nlp.model.wv and cluster_keyword in nlp.model.wv:
                        similarity = nlp.model.wv.similarity(book_keyword, cluster_keyword)
                        book_cluster_similarities.append(similarity)
                except:
                    continue
        
        if book_cluster_similarities:
            avg_book_cluster_similarity = np.mean(book_cluster_similarities)
            # í´ëŸ¬ìŠ¤í„° ë§¤ì¹­ ì ìˆ˜ = í‚¤ì›Œë“œ-í´ëŸ¬ìŠ¤í„° ìœ ì‚¬ë„ * ì±…-í´ëŸ¬ìŠ¤í„° ìœ ì‚¬ë„
            cluster_score = avg_cluster_similarity * avg_book_cluster_similarity
            if cluster_score > 0.1:  # ì„ê³„ê°’
                cluster_matches.append((isbn, cluster_score))
    
    cluster_matches.sort(key=lambda x: x[1], reverse=True)
    return cluster_matches[:top_k]

def combine_matches(direct_matches, similarity_matches, cluster_matches):
    """ë§¤ì¹­ ê²°ê³¼ í†µí•© ë° ê°€ì¤‘ì¹˜ ì ìš©"""
    combined = defaultdict(float)
    
    # ì§ì ‘ ë§¤ì¹­: ê°€ì¤‘ì¹˜ 1.0
    for isbn, score in direct_matches:
        combined[isbn] += score * 1.0
    
    # ìœ ì‚¬ë„ ë§¤ì¹­: ê°€ì¤‘ì¹˜ 0.8
    for isbn, score in similarity_matches:
        combined[isbn] += score * 0.8
    
    # í´ëŸ¬ìŠ¤í„° ë§¤ì¹­: ê°€ì¤‘ì¹˜ 0.6
    for isbn, score in cluster_matches:
        combined[isbn] += score * 0.6
    
    # ì ìˆ˜ ì •ê·œí™” (0-1 ë²”ìœ„)
    if combined:
        max_score = max(combined.values())
        if max_score > 0:
            combined = {isbn: score/max_score for isbn, score in combined.items()}
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_matches = sorted(combined.items(), key=lambda x: x[1], reverse=True)
    return sorted_matches

def evaluate_recommendation_quality():
    """ì¶”ì²œ í’ˆì§ˆ í‰ê°€"""
    db = MySQLDatabase()
    
    # ìµœê·¼ ì¶”ì²œ ê²°ê³¼ ë¶„ì„
    query = """
        SELECT r.books_isbn, r.similarity_score, b.books_title, n.news_keyword, n.news_category
        FROM tb_recommend r
        JOIN tb_books b ON r.books_isbn = b.books_isbn
        JOIN tb_news_keyword n ON r.news_id = n.news_id
        WHERE r.similarity_score IS NOT NULL
        ORDER BY r.similarity_score DESC
        LIMIT 100
    """
    
    results = db.fetch_query(query)
    
    if not results:
        print("ğŸ“Š í‰ê°€í•  ì¶”ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í†µê³„ ê³„ì‚°
    scores = [float(row[1]) for row in results if row[1] is not None]
    
    print("ğŸ“Š ì¶”ì²œ í’ˆì§ˆ í‰ê°€ ê²°ê³¼:")
    print(f"   - ì´ ì¶”ì²œ ìˆ˜: {len(results)}")
    print(f"   - í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜: {np.mean(scores):.4f}")
    print(f"   - ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜: {np.max(scores):.4f}")
    print(f"   - ìµœì € ìœ ì‚¬ë„ ì ìˆ˜: {np.min(scores):.4f}")
    print(f"   - í‘œì¤€í¸ì°¨: {np.std(scores):.4f}")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
    category_scores = defaultdict(list)
    for row in results:
        category = row[4]
        score = float(row[1]) if row[1] is not None else 0
        category_scores[category].append(score)
    
    print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì ìˆ˜:")
    for category, scores_list in category_scores.items():
        avg_score = np.mean(scores_list)
        print(f"   - {category}: {avg_score:.4f} ({len(scores_list)}ê°œ)")
    
    db.close()

if __name__ == "__main__":
    # ê¸°ì¡´ ì¶”ì²œ ì‹œìŠ¤í…œ (í˜¸í™˜ì„± ìœ ì§€)
    def recommend_books_by_keywords(news_data: dict):
        recommend_books_by_keywords_enhanced(news_data)
    
    crawler = Crowling()
    print("ğŸ“¡ ì¤‘ì•™ì¼ë³´ ë‰´ìŠ¤ í‚¤ì›Œë“œ í¬ë¡¤ë§ ì¤‘...")
    news_data = crawler.wordExtraction()
    print("âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ:", news_data)

    print("ğŸ“˜ í–¥ìƒëœ ì¶”ì²œ ë„ì„œ ì¶”ì¶œ ë° ì €ì¥ ì¤‘...")
    recommend_books_by_keywords_enhanced(news_data)
    print("âœ… í–¥ìƒëœ ì¶”ì²œ ì™„ë£Œ ë° DB ì €ì¥ ì™„ë£Œ")
    
    # ì¶”ì²œ í’ˆì§ˆ í‰ê°€
    print("\nğŸ” ì¶”ì²œ í’ˆì§ˆ í‰ê°€ ì¤‘...")
    evaluate_recommendation_quality()

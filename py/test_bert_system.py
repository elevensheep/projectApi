#!/usr/bin/env python3
"""
BERT ê¸°ë°˜ í–¥ìƒëœ NLP ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.bert_nlp import BertNLP
from app.services.database import MySQLDatabase
from app.utils.bert_recommendation import BertRecommendationSystem
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_bert_nlp():
    """BERT NLP ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ BERT NLP ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        # BERT NLP ì´ˆê¸°í™”
        print("ğŸ¤– BERT NLP ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        bert_nlp = BertNLP()
        print("âœ… BERT NLP ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 1. ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        print("\nğŸ” 1. ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸...")
        test_pairs = [
            ("ê²½ì œ ìœ„ê¸°", "ê¸ˆìœµ ì‹œì¥ì˜ ë¶ˆì•ˆì •ì„±"),
            ("ì •ì¹˜ ê°œí˜", "ë¯¼ì£¼ì£¼ì˜ ë°œì „"),
            ("ìŠ¤í¬ì¸  ê²½ê¸°", "ì¶•êµ¬ ì„ ìˆ˜ë“¤ì˜ í™œì•½"),
            ("êµìœ¡ í˜ì‹ ", "ë¯¸ë˜ ì¸ì¬ ì–‘ì„±"),
            ("ê¸°ìˆ  ë°œì „", "ê³¼í•™ ì—°êµ¬ì˜ ìµœì‹  ë™í–¥")
        ]
        
        for text1, text2 in test_pairs:
            similarity = bert_nlp.calculate_contextual_similarity(text1, text2)
            print(f"  '{text1}' â†” '{text2}': {similarity:.4f}")
        
        # 2. ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸
        print("\nğŸ˜Š 2. ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸...")
        test_texts = [
            "ì´ ì±…ì€ ì •ë§ í›Œë¥­í•˜ê³  ê°ë™ì ì¸ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.",
            "ìŠ¬í”„ê³  ë¹„ê·¹ì ì¸ ì´ì•¼ê¸°ë¡œ ê°€ìŠ´ì´ ì•„í”•ë‹ˆë‹¤.",
            "ì¼ë°˜ì ì¸ ê²½ì œ ì´ë¡ ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.",
            "í¬ë§ì ì´ê³  ë°ì€ ë¯¸ë˜ë¥¼ ê·¸ë¦¬ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.",
            "í™”ê°€ ë‚˜ê³  ì‹¤ë§ìŠ¤ëŸ¬ìš´ ìƒí™©ì„ ë‹¤ë£¹ë‹ˆë‹¤."
        ]
        
        for text in test_texts:
            sentiment = bert_nlp.analyze_sentiment(text)
            dominant = bert_nlp.get_dominant_sentiment(text)
            print(f"  '{text[:30]}...' â†’ {dominant} (ê¸ì •: {sentiment['positive']:.3f}, ë¶€ì •: {sentiment['negative']:.3f}, ì¤‘ë¦½: {sentiment['neutral']:.3f})")
        
        # 3. ìœ ì‚¬ í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\nğŸ” 3. ìœ ì‚¬ í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
        query = "ê²½ì œ ë°œì „ê³¼ ì„±ì¥"
        candidates = [
            "ê²½ì œ ìœ„ê¸°ì™€ ê¸ˆìœµ ì‹œì¥ì˜ ë³€í™”",
            "ì •ì¹˜ ê°œí˜ê³¼ ë¯¼ì£¼ì£¼ì˜ ë°œì „",
            "ìŠ¤í¬ì¸  ì„ ìˆ˜ë“¤ì˜ ê²½ê¸°ë ¥ í–¥ìƒ",
            "ê¸ˆìœµ ì •ì±…ê³¼ ê²½ì œ ì„±ì¥",
            "êµìœ¡ í˜ì‹ ê³¼ ë¯¸ë˜ ì¸ì¬ ì–‘ì„±"
        ]
        
        similar_texts = bert_nlp.find_similar_texts(query, candidates, top_k=3)
        print(f"  ì¿¼ë¦¬: '{query}'")
        for idx, score in similar_texts:
            print(f"    - '{candidates[idx]}': {score:.4f}")
        
        # 4. í…ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š 4. í…ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸...")
        clustering_texts = [
            "ê²½ì œ ìœ„ê¸°ì™€ ê¸ˆìœµ ì‹œì¥ì˜ ë³€í™”ì— ëŒ€í•œ ë¶„ì„",
            "ì •ì¹˜ ê°œí˜ê³¼ ë¯¼ì£¼ì£¼ì˜ ë°œì „ ë°©í–¥",
            "ìŠ¤í¬ì¸  ì„ ìˆ˜ë“¤ì˜ ê²½ê¸°ë ¥ í–¥ìƒ ë°©ë²•",
            "êµìœ¡ í˜ì‹ ê³¼ ë¯¸ë˜ ì¸ì¬ ì–‘ì„±",
            "ê¸°ìˆ  ë°œì „ê³¼ ê³¼í•™ ì—°êµ¬ì˜ ìµœì‹  ë™í–¥",
            "ê¸ˆìœµ ì •ì±…ê³¼ ê²½ì œ ì„±ì¥ ì „ëµ",
            "ì •ì¹˜ ìŠ¤ìº”ë“¤ê³¼ ë¶€íŒ¨ ë¬¸ì œ",
            "ì¶•êµ¬ ê²½ê¸°ì™€ ì„ ìˆ˜ë“¤ì˜ í™œì•½",
            "ëŒ€í•™ êµìœ¡ê³¼ í•™ìƒë“¤ì˜ í•™ìŠµ",
            "ì¸ê³µì§€ëŠ¥ê³¼ ë¯¸ë˜ ê¸°ìˆ "
        ]
        
        clusters = bert_nlp.cluster_texts(clustering_texts, n_clusters=3)
        print(f"  í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼: {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„°")
        for cluster_id, text_indices in clusters.items():
            print(f"    í´ëŸ¬ìŠ¤í„° {cluster_id}: {len(text_indices)}ê°œ í…ìŠ¤íŠ¸")
            for idx in text_indices[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"      - {clustering_texts[idx][:30]}...")
        
        # 5. ì„ë² ë”© ì‹œê°í™” í…ŒìŠ¤íŠ¸
        print("\nğŸ“ˆ 5. ì„ë² ë”© ì‹œê°í™” í…ŒìŠ¤íŠ¸...")
        try:
            bert_nlp.visualize_embeddings(
                clustering_texts[:8],  # 8ê°œë§Œ ì‚¬ìš©
                title="BERT ì„ë² ë”© ì‹œê°í™” í…ŒìŠ¤íŠ¸"
            )
            print("âœ… ì„ë² ë”© ì‹œê°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ì‹œê°í™” ì‹¤íŒ¨: {e}")
        
        # 6. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        print("\nâš¡ 6. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        start_time = time.time()
        embeddings = bert_nlp.batch_process(clustering_texts, batch_size=4)
        end_time = time.time()
        
        print(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥: {len(clustering_texts)}ê°œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì‹œê°„ {end_time - start_time:.4f}ì´ˆ")
        print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {(end_time - start_time) / len(clustering_texts):.4f}ì´ˆ/í…ìŠ¤íŠ¸")
        
        print("\nğŸ‰ BERT NLP ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ BERT NLP í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def test_bert_recommendation():
    """BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ¯ BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •...")
        db = MySQLDatabase()
        db.add_similarity_score_column()
        db.add_method_column()
        db.update_similarity_scores()
        db.update_method_values()
        
        # BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸ¤– BERT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        bert_rec = BertRecommendationSystem()
        
        # í…ŒìŠ¤íŠ¸ìš© ë‰´ìŠ¤ ë°ì´í„°
        test_news_data = {
            'economy': ['ê²½ì œ', 'ê¸ˆìœµ', 'íˆ¬ì', 'ì£¼ì‹'],
            'politics': ['ì •ì¹˜', 'ì •ë¶€', 'êµ­íšŒ', 'ëŒ€í†µë ¹'],
            'sports': ['ìŠ¤í¬ì¸ ', 'ì¶•êµ¬', 'ì•¼êµ¬', 'ì„ ìˆ˜']
        }
        
        # 1. ë¬¸ë§¥ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        print("\nğŸ” 1. ë¬¸ë§¥ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
        context_recs = bert_rec.recommend_books_by_context(test_news_data)
        for category, recs in context_recs.items():
            print(f"  {category}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"    - {isbn}: {score:.4f}")
        
        # 2. ê°ì • ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        print("\nğŸ˜Š 2. ê°ì • ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
        sentiment_recs = bert_rec.recommend_books_by_sentiment(test_news_data)
        for keyword, recs in sentiment_recs.items():
            print(f"  {keyword}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"    - {isbn}: {score:.4f}")
        
        # 3. í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š 3. í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
        cluster_recs = bert_rec.recommend_books_by_clustering(test_news_data, n_clusters=3)
        for category, recs in cluster_recs.items():
            print(f"  {category}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"    - {isbn}: {score:.4f}")
        
        # 4. í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        print("\nğŸš€ 4. í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
        hybrid_recs = bert_rec.hybrid_recommendation(test_news_data)
        for category, recs in hybrid_recs.items():
            print(f"  {category}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"    - {isbn}: {score:.4f}")
        
        # 5. DB ì €ì¥ í…ŒìŠ¤íŠ¸
        print("\nğŸ’¾ 5. DB ì €ì¥ í…ŒìŠ¤íŠ¸...")
        bert_rec.save_recommendations_to_db(hybrid_recs, "hybrid")
        
        # 6. í’ˆì§ˆ í‰ê°€
        print("\nğŸ“ˆ 6. í’ˆì§ˆ í‰ê°€...")
        bert_rec.evaluate_recommendation_quality("hybrid")
        
        bert_rec.close()
        db.close()
        
        print("\nğŸ‰ BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def compare_methods():
    """ê¸°ì¡´ ë°©ë²•ê³¼ BERT ë°©ë²• ë¹„êµ"""
    print("\nâš–ï¸ ê¸°ì¡´ ë°©ë²• vs BERT ë°©ë²• ë¹„êµ")
    print("=" * 40)
    
    try:
        from app.services.nlp import Nlp
        from app.utils.recommendation_runner import recommend_books_by_keywords_enhanced
        
        # í…ŒìŠ¤íŠ¸ìš© ë‰´ìŠ¤ ë°ì´í„°
        test_news_data = {
            'economy': ['ê²½ì œ', 'ê¸ˆìœµ'],
            'politics': ['ì •ì¹˜', 'ì •ë¶€']
        }
        
        # 1. ê¸°ì¡´ Word2Vec ë°©ë²•
        print("ğŸ“Š 1. ê¸°ì¡´ Word2Vec ë°©ë²•...")
        start_time = time.time()
        
        nlp = Nlp()
        nlp.LoadModel()
        
        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        test_words = [("ê²½ì œ", "ê¸ˆìœµ"), ("ì •ì¹˜", "ì •ë¶€")]
        for word1, word2 in test_words:
            nlp.ModelScore(word1, word2)
        
        w2v_time = time.time() - start_time
        print(f"   Word2Vec ì²˜ë¦¬ ì‹œê°„: {w2v_time:.4f}ì´ˆ")
        
        # 2. BERT ë°©ë²•
        print("ğŸ¤– 2. BERT ë°©ë²•...")
        start_time = time.time()
        
        bert_nlp = BertNLP()
        
        # ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        test_texts = [("ê²½ì œ ë°œì „", "ê¸ˆìœµ ì‹œì¥"), ("ì •ì¹˜ ê°œí˜", "ì •ë¶€ ì •ì±…")]
        for text1, text2 in test_texts:
            similarity = bert_nlp.calculate_contextual_similarity(text1, text2)
            print(f"   '{text1}' â†” '{text2}': {similarity:.4f}")
        
        bert_time = time.time() - start_time
        print(f"   BERT ì²˜ë¦¬ ì‹œê°„: {bert_time:.4f}ì´ˆ")
        
        # 3. ì„±ëŠ¥ ë¹„êµ
        print("\nğŸ“ˆ 3. ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
        print(f"   Word2Vec: {w2v_time:.4f}ì´ˆ")
        print(f"   BERT: {bert_time:.4f}ì´ˆ")
        print(f"   ì„±ëŠ¥ ë¹„ìœ¨: {bert_time/w2v_time:.2f}ë°° (BERTê°€ ë” ëŠë¦¼)")
        print("   ğŸ’¡ BERTëŠ” ë” ì •í™•í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.")
        
        print("\nğŸ‰ ë°©ë²• ë¹„êµ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë°©ë²• ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    try:
        test_bert_nlp()
        test_bert_recommendation()
        compare_methods()
        
        print("\n" + "="*60)
        print("ğŸ‰ ëª¨ë“  BERT ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*60)
        
    except Exception as e:
        print(f"âŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc() 
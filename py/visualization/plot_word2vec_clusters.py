#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Word2Vec ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‹¨ì–´ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
from collections import Counter
import platform

def load_word2vec_model():
    """Word2Vec ëª¨ë¸ ë¡œë“œ"""
    try:
        from gensim.models import Word2Vec
        model_path = "word2vec.model"
        
        if os.path.exists(model_path):
            model = Word2Vec.load(model_path)
            print(f"âœ… Word2Vec ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“Š ëª¨ë¸ ì–´íœ˜ í¬ê¸°: {len(model.wv.key_to_index)}")
            return model
        else:
            print("âŒ word2vec.model íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def get_word_vectors(model, word_list=None, max_words=None):
    """ë‹¨ì–´ ë²¡í„° ì¶”ì¶œ"""
    if word_list is None:
        if max_words is None:
            # ì „ì²´ ë‹¨ì–´ ì‚¬ìš©
            word_list = list(model.wv.key_to_index)
        else:
            # ìƒìœ„ ë¹ˆë„ ë‹¨ì–´ë“¤ ì„ íƒ
            word_list = list(model.wv.key_to_index)[:max_words]
    
    # ëª¨ë¸ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ë§Œ í•„í„°ë§
    valid_words = [word for word in word_list if word in model.wv]
    word_vectors = np.array([model.wv[word] for word in valid_words])
    
    print(f"ğŸ“Š {len(valid_words)}ê°œì˜ ë‹¨ì–´ ë²¡í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
    return valid_words, word_vectors

def find_optimal_clusters_elbow(word_vectors, max_clusters=15):
    """ì—˜ë³´ìš° ê¸°ë²•ìœ¼ë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸°"""
    print("ğŸ” ì—˜ë³´ìš° ê¸°ë²•ìœ¼ë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì°¾ëŠ” ì¤‘...")
    
    cluster_range = range(1, min(max_clusters + 1, len(word_vectors)))
    inertias = []
    silhouette_scores = []
    
    for n_clusters in cluster_range:
        if n_clusters == 1:
            inertia = np.sum([np.sum((word_vectors - np.mean(word_vectors, axis=0))**2)])
            inertias.append(inertia)
            silhouette_scores.append(0)
        else:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(word_vectors)
            inertias.append(kmeans.inertia_)
            
            if len(set(labels)) > 1:
                silhouette_scores.append(silhouette_score(word_vectors, labels))
            else:
                silhouette_scores.append(0)
    
    # ì—˜ë³´ìš° í¬ì¸íŠ¸ ì°¾ê¸°
    if len(inertias) > 2:
        first_derivative = np.diff(inertias)
        second_derivative = np.diff(first_derivative)
        
        if len(second_derivative) > 0:
            elbow_idx = np.argmax(second_derivative) + 2
            elbow_clusters = cluster_range[elbow_idx]
        else:
            elbow_clusters = 2
    else:
        elbow_clusters = 2
    
    # ì‹¤ë£¨ì—£ ì ìˆ˜ ê¸°ë°˜ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜
    if len(silhouette_scores) > 1:
        silhouette_optimal = cluster_range[np.argmax(silhouette_scores[1:]) + 1]
    else:
        silhouette_optimal = 2
    
    print(f"ğŸ“Š ì—˜ë³´ìš° ê¸°ë²• ê²°ê³¼: {elbow_clusters}ê°œ í´ëŸ¬ìŠ¤í„°")
    print(f"ğŸ“Š ì‹¤ë£¨ì—£ ì ìˆ˜ ê¸°ë°˜: {silhouette_optimal}ê°œ í´ëŸ¬ìŠ¤í„°")
    print(f"ğŸ“Š ìµœê³  ì‹¤ë£¨ì—£ ì ìˆ˜: {max(silhouette_scores):.4f}")
    
    return elbow_clusters, inertias, silhouette_scores, cluster_range

def plot_elbow_method(inertias, silhouette_scores, cluster_range, optimal_clusters):
    """ì—˜ë³´ìš° ê¸°ë²• ì‹œê°í™”"""
    # ê·¸ë˜í”„ ì„¤ì •
    if platform.system() == "Windows":
        plt.rcParams['font.family'] = 'Malgun Gothic'
    else:
        plt.rcParams['font.family'] = 'Nanum Gothic'
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # ì—˜ë³´ìš° ê·¸ë˜í”„
    ax1.plot(cluster_range, inertias, 'bo-', linewidth=2, markersize=8)
    ax1.axvline(x=optimal_clusters, color='red', linestyle='--', linewidth=2, 
               label=f'ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {optimal_clusters}')
    ax1.set_xlabel('í´ëŸ¬ìŠ¤í„° ìˆ˜', fontsize=12)
    ax1.set_ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12)
    ax1.set_title('ì—˜ë³´ìš° ê¸°ë²• (Elbow Method)', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # ì‹¤ë£¨ì—£ ì ìˆ˜ ê·¸ë˜í”„
    if len(silhouette_scores) > 1:
        ax2.plot(cluster_range[1:], silhouette_scores[1:], 'go-', linewidth=2, markersize=8)
        silhouette_optimal = cluster_range[np.argmax(silhouette_scores[1:]) + 1]
        ax2.axvline(x=silhouette_optimal, color='red', linestyle='--', linewidth=2,
                   label=f'ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {silhouette_optimal}')
        ax2.set_xlabel('í´ëŸ¬ìŠ¤í„° ìˆ˜', fontsize=12)
        ax2.set_ylabel('Silhouette Score', fontsize=12)
        ax2.set_title('ì‹¤ë£¨ì—£ ì ìˆ˜ (Silhouette Score)', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
    
    plt.tight_layout()
    plt.savefig("word2vec_elbow_analysis.png", dpi=300, bbox_inches='tight')
    print("ğŸ“Š ì—˜ë³´ìš° ë¶„ì„ ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: word2vec_elbow_analysis.png")
    plt.show()

def reduce_dimensions(word_vectors):
    """ì°¨ì› ì¶•ì†Œ (PCA + t-SNE)"""
    print("ğŸ” ì°¨ì›ì„ ì¶•ì†Œí•˜ëŠ” ì¤‘...")
    
    # PCAë¡œ ë¨¼ì € ì°¨ì› ì¶•ì†Œ
    pca = PCA(n_components=min(50, len(word_vectors[0])))
    word_vectors_pca = pca.fit_transform(word_vectors)
    
    # t-SNEë¡œ 2Dë¡œ ì¶•ì†Œ
    tsne = TSNE(
        n_components=2,
        perplexity=min(30, len(word_vectors) - 1),
        learning_rate=200,
        n_iter=1000,
        random_state=42,
        init='pca'
    )
    reduced_vectors = tsne.fit_transform(word_vectors_pca)
    
    print("âœ… ì°¨ì› ì¶•ì†Œ ì™„ë£Œ")
    return reduced_vectors

def plot_word_clusters(words, reduced_vectors, labels, optimal_clusters):
    """ë‹¨ì–´ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”"""
    # ê·¸ë˜í”„ ì„¤ì •
    if platform.system() == "Windows":
        plt.rcParams['font.family'] = 'Malgun Gothic'
    else:
        plt.rcParams['font.family'] = 'Nanum Gothic'
    
    # ìƒ‰ìƒ ì„¤ì •
    unique_labels = set(labels)
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    point_colors = [color_map[label] for label in labels]
    
    plt.figure(figsize=(20, 15))
    scatter = plt.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1], 
                         c=point_colors, alpha=0.7, s=50)
    
    # ë‹¨ì–´ ë¼ë²¨ í‘œì‹œ (ì¤‘ìš”í•œ ë‹¨ì–´ë§Œ)
    word_freq = Counter(words)
    important_words = [word for word in words if word_freq[word] > 1 or len(word) > 2]
    
    for i, word in enumerate(words):
        if word in important_words:
            plt.annotate(word, (reduced_vectors[i, 0] + 0.5, reduced_vectors[i, 1] + 0.5), 
                       fontsize=9, alpha=0.8, fontweight='bold')
    
    # ë²”ë¡€
    legend_elements = []
    for label in unique_labels:
        if label != -1:  # DBSCANì˜ ë…¸ì´ì¦ˆ í´ëŸ¬ìŠ¤í„° ì œì™¸
            cluster_words = [words[i] for i, l in enumerate(labels) if l == label]
            if cluster_words:
                # ëŒ€í‘œ ë‹¨ì–´ ì„ íƒ (ê°€ì¥ ê¸´ ë‹¨ì–´ ë˜ëŠ” ë¹ˆë„ê°€ ë†’ì€ ë‹¨ì–´)
                representative_word = max(cluster_words, key=lambda w: len(w))
                legend_elements.append(
                    plt.Line2D([0], [0], marker='o', color='w', 
                              markerfacecolor=color_map[label], 
                              markersize=10, label=f"í´ëŸ¬ìŠ¤í„° {label}: {representative_word}")
                )
    
    plt.legend(handles=legend_elements, title="ğŸ“Œ í´ëŸ¬ìŠ¤í„° ëŒ€í‘œ ë‹¨ì–´", 
              loc="upper left", bbox_to_anchor=(0, 1), fontsize=10)
    
    plt.title(f"Word2Vec ë‹¨ì–´ ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§ (K-means, K={optimal_clusters})", fontsize=16)
    plt.xlabel("t-SNE-1", fontsize=12)
    plt.ylabel("t-SNE-2", fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig("word2vec_clusters.png", dpi=300, bbox_inches='tight')
    print("ğŸ“Š ë‹¨ì–´ í´ëŸ¬ìŠ¤í„° ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: word2vec_clusters.png")
    plt.show()

def analyze_clusters(words, labels, optimal_clusters):
    """í´ëŸ¬ìŠ¤í„° ë¶„ì„ ë° ë‹¨ì–´ ì¶œë ¥"""
    print(f"\nğŸ“Š í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼ (K={optimal_clusters}):")
    
    # í´ëŸ¬ìŠ¤í„°ë³„ ë‹¨ì–´ ê·¸ë£¹í™”
    cluster_groups = {}
    for i, (word, label) in enumerate(zip(words, labels)):
        if label not in cluster_groups:
            cluster_groups[label] = []
        cluster_groups[label].append(word)
    
    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ë‹¨ì–´ë“¤ ì¶œë ¥
    for cluster_id in sorted(cluster_groups.keys()):
        cluster_words = cluster_groups[cluster_id]
        print(f"\nğŸ”¸ í´ëŸ¬ìŠ¤í„° {cluster_id} ({len(cluster_words)}ê°œ ë‹¨ì–´):")
        
        # ë‹¨ì–´ë¥¼ ê¸¸ì´ì™€ ë¹ˆë„ë¡œ ì •ë ¬
        sorted_words = sorted(cluster_words, key=lambda w: (len(w), w), reverse=True)
        
        # ë‹¨ì–´ë“¤ì„ 10ê°œì”© ì¶œë ¥
        for i in range(0, len(sorted_words), 10):
            batch = sorted_words[i:i+10]
            print(f"   {', '.join(batch)}")
        
        if len(sorted_words) > 10:
            print(f"   ... (ì´ {len(sorted_words)}ê°œ ë‹¨ì–´)")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ”¬ Word2Vec ë‹¨ì–´ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™” í”„ë¡œê·¸ë¨")
    print("=" * 60)
    print()
    
    # Word2Vec ëª¨ë¸ ë¡œë“œ
    model = load_word2vec_model()
    if model is None:
        print("âŒ Word2Vec ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë‹¨ì–´ ë²¡í„° ì¶”ì¶œ (ë” ë§ì€ ë‹¨ì–´ ì‚¬ìš©)
    words, word_vectors = get_word_vectors(model, max_words=1000)
    
    if len(word_vectors) < 10:
        print("âŒ ì¶©ë¶„í•œ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 10ê°œ ì´ìƒì˜ ë‹¨ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    # K=30ìœ¼ë¡œ ì„¤ì • (ì‹¤ë£¨ì—£ ì ìˆ˜ 0.5 ì´ìƒ ëª©í‘œ)
    optimal_clusters = 30
    print(f"ğŸ¯ ì‹¤ë£¨ì—£ ì ìˆ˜ 0.5 ì´ìƒì„ ìœ„í•´ K={optimal_clusters}ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
    
    # ì—˜ë³´ìš° ê·¸ë˜í”„ëŠ” ìƒëµí•˜ê³  ë°”ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ì§„í–‰
    print(f"\nğŸ“Š K={optimal_clusters} í´ëŸ¬ìŠ¤í„°ë§ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
    
    # ì°¨ì› ì¶•ì†Œ
    reduced_vectors = reduce_dimensions(word_vectors)
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§
    print(f"\nğŸ” {optimal_clusters}ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ K-means í´ëŸ¬ìŠ¤í„°ë§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(reduced_vectors)
    
    # í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ í‰ê°€
    if len(set(labels)) > 1:
        silhouette_avg = silhouette_score(reduced_vectors, labels)
        print(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ - ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_avg:.4f}")
    
    # ë‹¨ì–´ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”
    print("\nğŸ“Š ë‹¨ì–´ í´ëŸ¬ìŠ¤í„° ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    plot_word_clusters(words, reduced_vectors, labels, optimal_clusters)
    
    # í´ëŸ¬ìŠ¤í„° ë¶„ì„ ë° ë‹¨ì–´ ì¶œë ¥
    analyze_clusters(words, labels, optimal_clusters)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Word2Vec ë‹¨ì–´ í´ëŸ¬ìŠ¤í„°ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print("   - word2vec_elbow_analysis.png (ì—˜ë³´ìš° ë¶„ì„)")
    print("   - word2vec_clusters.png (ë‹¨ì–´ í´ëŸ¬ìŠ¤í„°)")
    print("=" * 60)

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
BERT ê¸°ë°˜ NLP ë° ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
- ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ ë§¤ì¹­
- í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ
- í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ì¶”ì²œ
"""

import sys
import os
import logging
from typing import List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from py.app.services.bert_nlp import BertNLP
from py.app.utils.bert_recommendation import BertRecommendationSystem
from py.app.services.database import MySQLDatabase

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_bert_nlp():
    """BERT NLP ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª BERT NLP ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # BERT NLP ì´ˆê¸°í™”
        bert_nlp = BertNLP()
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë“¤
        test_texts = [
            "ê²½ì œ ìœ„ê¸°ì™€ íˆ¬ì ì „ëµ",
            "ì£¼ì‹ ì‹œì¥ ë¶„ì„ê³¼ íˆ¬ì ë°©ë²•",
            "ì‚¬íšŒ ë¬¸ì œì™€ í•´ê²°ì±…",
            "ì •ì¹˜ í˜„ì•ˆê³¼ ë¯¼ì£¼ì£¼ì˜",
            "ìŠ¤í¬ì¸  ê²½ê¸° ê²°ê³¼ì™€ ì„ ìˆ˜ ë¶„ì„"
        ]
        
        # 1. ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸
        logger.info("ğŸ“Š ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸")
        text1 = "ê²½ì œ ìœ„ê¸°ì™€ íˆ¬ì ì „ëµ"
        text2 = "ì£¼ì‹ ì‹œì¥ ë¶„ì„ê³¼ íˆ¬ì ë°©ë²•"
        similarity = bert_nlp.calculate_contextual_similarity(text1, text2)
        logger.info(f"  '{text1}' vs '{text2}': {similarity:.4f}")
        
        # 2. ìœ ì‚¬ í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ” ìœ ì‚¬ í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        query = "ê²½ì œ íˆ¬ì"
        similar_texts = bert_nlp.find_similar_texts(query, test_texts, top_k=3)
        logger.info(f"  ì¿¼ë¦¬: '{query}'")
        for idx, score in similar_texts:
            logger.info(f"    - {test_texts[idx]}: {score:.4f}")
        
        # 3. í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        sample_text = "ê²½ì œ ìœ„ê¸° ìƒí™©ì—ì„œ íˆ¬ììë“¤ì´ ì·¨í•´ì•¼ í•  ì „ëµê³¼ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ë°©ë²•"
        keywords = bert_nlp.extract_keywords(sample_text, top_k=5)
        logger.info(f"  í…ìŠ¤íŠ¸: '{sample_text}'")
        logger.info(f"  í‚¤ì›Œë“œ: {keywords}")
        
        # 4. ë‹¨ì–´ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸
        logger.info("ğŸ“ˆ ë‹¨ì–´ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸")
        word_pairs = [
            ("ê²½ì œ", "íˆ¬ì"),
            ("ì£¼ì‹", "ì‹œì¥"),
            ("ì‚¬íšŒ", "ë¬¸ì œ"),
            ("ì •ì¹˜", "ë¯¼ì£¼ì£¼ì˜")
        ]
        for word1, word2 in word_pairs:
            similarity = bert_nlp.calculate_word_similarity(word1, word2)
            logger.info(f"  '{word1}' vs '{word2}': {similarity:.4f}")
        
        # 5. í…ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ“Š í…ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸")
        clusters = bert_nlp.cluster_texts(test_texts, n_clusters=3)
        for cluster_id, text_indices in clusters.items():
            logger.info(f"  í´ëŸ¬ìŠ¤í„° {cluster_id}:")
            for idx in text_indices:
                logger.info(f"    - {test_texts[idx]}")
        
        # 6. ì„ë² ë”© ì‹œê°í™” í…ŒìŠ¤íŠ¸ (ì˜µì…˜)
        logger.info("ğŸ“ˆ ì„ë² ë”© ì‹œê°í™” í…ŒìŠ¤íŠ¸")
        try:
            bert_nlp.visualize_embeddings(test_texts, title="í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì„ë² ë”©")
            logger.info("  âœ… ì‹œê°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"  âš ï¸ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        
        # 7. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        logger.info("âš¡ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        embeddings = bert_nlp.batch_process(test_texts, batch_size=2)
        logger.info(f"  ë°°ì¹˜ ì²˜ë¦¬ëœ ì„ë² ë”© ìˆ˜: {len(embeddings)}")
        
        # 8. í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ”§ í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        features = bert_nlp.get_text_features(sample_text)
        logger.info(f"  í…ìŠ¤íŠ¸ ê¸¸ì´: {features['length']}")
        logger.info(f"  ë‹¨ì–´ ìˆ˜: {features['word_count']}")
        logger.info(f"  í‚¤ì›Œë“œ: {features['keywords']}")
        
        logger.info("âœ… BERT NLP ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ BERT NLP í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_bert_recommendation():
    """BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        recommender = BertRecommendationSystem()
        
        # ì‹¤ì œ ë‰´ìŠ¤ ì œëª©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        from py.app.services.crowling import Crowling
        crawler = Crowling()
        
        logger.info("ğŸ“¡ ì‹¤ì œ ë‰´ìŠ¤ ì œëª© í¬ë¡¤ë§ ì¤‘...")
        news_titles = crawler.get_news_titles()
        
        if not news_titles:
            logger.warning("âš ï¸ ë‰´ìŠ¤ ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©")
            # í…ŒìŠ¤íŠ¸ìš© ë‰´ìŠ¤ ë°ì´í„°
            news_titles = {
                "ê²½ì œ": ["ì£¼ì‹ íˆ¬ì", "ê²½ì œ ìœ„ê¸°", "íˆ¬ì ì „ëµ"],
                "ì‚¬íšŒ": ["ì‚¬íšŒ ë¬¸ì œ", "í•´ê²°ì±…", "ê°œì„  ë°©ì•ˆ"],
                "ì •ì¹˜": ["ì •ì¹˜ í˜„ì•ˆ", "ë¯¼ì£¼ì£¼ì˜", "ì •ì±…"]
            }
        
        logger.info(f"ğŸ“° í…ŒìŠ¤íŠ¸ìš© ë‰´ìŠ¤ ì œëª©: {len(news_titles)}ê°œ ì¹´í…Œê³ ë¦¬")
        
        # 1. ë¬¸ë§¥ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ§  ë¬¸ë§¥ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
        context_recs = recommender.recommend_books_by_context(news_titles)
        for category, recs in context_recs.items():
            logger.info(f"  {category}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                logger.info(f"    - {isbn}: {score:.4f}")
        
        # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
        keyword_recs = recommender.recommend_books_by_keywords(news_titles)
        for keyword, recs in keyword_recs.items():
            logger.info(f"  {keyword}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:
                logger.info(f"    - {isbn}: {score:.4f}")
        
        # 3. í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
        cluster_recs = recommender.recommend_books_by_clustering(news_titles, n_clusters=3)
        for keyword, recs in cluster_recs.items():
            logger.info(f"  {keyword}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:
                logger.info(f"    - {isbn}: {score:.4f}")
        
        # 4. í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
        hybrid_recs = recommender.hybrid_recommendation(news_titles)
        for keyword, recs in hybrid_recs.items():
            logger.info(f"  {keyword}: {len(recs)}ê°œ ì¶”ì²œ")
            for isbn, score in recs[:3]:
                logger.info(f"    - {isbn}: {score:.4f}")
        
        # 5. DB ì €ì¥ í…ŒìŠ¤íŠ¸ (ì˜µì…˜)
        logger.info("ğŸ’¾ DB ì €ì¥ í…ŒìŠ¤íŠ¸")
        try:
            recommender.save_recommendations_to_db(hybrid_recs, "test_hybrid")
            logger.info("  âœ… DB ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"  âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # 6. í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ“ˆ í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸")
        try:
            recommender.evaluate_recommendation_quality("test_hybrid")
        except Exception as e:
            logger.warning(f"  âš ï¸ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        recommender.close()
        
        logger.info("âœ… BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ BERT ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def compare_methods():
    """ì „í†µì  ë°©ë²•ê³¼ BERT ë°©ë²• ë¹„êµ"""
    logger.info("ğŸ”„ ì „í†µì  ë°©ë²•ê³¼ BERT ë°©ë²• ë¹„êµ")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_texts = [
            "ê²½ì œ ìœ„ê¸°ì™€ íˆ¬ì ì „ëµ",
            "ì£¼ì‹ ì‹œì¥ ë¶„ì„ê³¼ íˆ¬ì ë°©ë²•",
            "ì‚¬íšŒ ë¬¸ì œì™€ í•´ê²°ì±…"
        ]
        
        # BERT NLP ì´ˆê¸°í™”
        bert_nlp = BertNLP()
        
        # 1. ìœ ì‚¬ë„ ê³„ì‚° ë¹„êµ
        logger.info("ğŸ“Š ìœ ì‚¬ë„ ê³„ì‚° ë¹„êµ")
        text1 = "ê²½ì œ íˆ¬ì"
        text2 = "ì£¼ì‹ ì‹œì¥"
        
        # BERT ê¸°ë°˜ ìœ ì‚¬ë„
        bert_similarity = bert_nlp.calculate_contextual_similarity(text1, text2)
        logger.info(f"  BERT ìœ ì‚¬ë„: {bert_similarity:.4f}")
        
        # 2. í‚¤ì›Œë“œ ì¶”ì¶œ ë¹„êµ
        logger.info("ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ ë¹„êµ")
        sample_text = "ê²½ì œ ìœ„ê¸° ìƒí™©ì—ì„œ íˆ¬ììë“¤ì´ ì·¨í•´ì•¼ í•  ì „ëµ"
        
        # BERT ê¸°ë°˜ í‚¤ì›Œë“œ
        bert_keywords = bert_nlp.extract_keywords(sample_text, top_k=5)
        logger.info(f"  BERT í‚¤ì›Œë“œ: {bert_keywords}")
        
        # 3. ì„±ëŠ¥ ë¹„êµ
        logger.info("âš¡ ì„±ëŠ¥ ë¹„êµ")
        import time
        
        # BERT ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        for _ in range(10):
            bert_nlp.calculate_contextual_similarity(text1, text2)
        bert_time = time.time() - start_time
        
        logger.info(f"  BERT 10íšŒ ì²˜ë¦¬ ì‹œê°„: {bert_time:.4f}ì´ˆ")
        
        logger.info("âœ… ë°©ë²• ë¹„êµ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°©ë²• ë¹„êµ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ BERT ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        ("BERT NLP ê¸°ëŠ¥", test_bert_nlp),
        ("BERT ì¶”ì²œ ì‹œìŠ¤í…œ", test_bert_recommendation),
        ("ë°©ë²• ë¹„êµ", compare_methods)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ§ª {test_name} í…ŒìŠ¤íŠ¸")
        logger.info(f"{'='*50}")
        
        try:
            success = test_func()
            results[test_name] = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        except Exception as e:
            logger.error(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì˜ˆì™¸ ë°œìƒ: {e}")
            results[test_name] = "âŒ ì˜ˆì™¸"
    
    # ê²°ê³¼ ìš”ì•½
    logger.info(f"\n{'='*50}")
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info(f"{'='*50}")
    
    for test_name, result in results.items():
        logger.info(f"  {test_name}: {result}")
    
    success_count = sum(1 for result in results.values() if "ì„±ê³µ" in result)
    total_count = len(results)
    
    logger.info(f"\n  ì „ì²´ ì„±ê³µë¥ : {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
    
    if success_count == total_count:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    else:
        logger.warning("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    
    logger.info("ğŸ BERT ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    main() 
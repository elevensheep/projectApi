import requests
from bs4 import BeautifulSoup
from konlpy.tag import Okt
import mysql.connector
from collections import Counter
from datetime import datetime

# MySQL ì—°ê²° ì„¤ì • (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
DB_CONFIG = {
    "host": "127.0.0.1",
    "port": 3306,
    "user": "root",
    "password": "1111",  # ì˜¬ë°”ë¥¸ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
    "database": "book"
}

class MySQLDatabase:
    def __init__(self):
        """MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        self.conn = mysql.connector.connect(**DB_CONFIG)
        self.cursor = self.conn.cursor()

    def insert_top_keywords(self, section, keywords):
        """ìƒìœ„ 10ê°œ ë‹¨ì–´ì™€ í˜„ì¬ datetimeì„ tb_newsKeyword í…Œì´ë¸”ì— ì €ì¥"""
        query = "INSERT INTO tb_newsKeyword (news_date, news_keyword) VALUES (%s, %s)"
        now = datetime.now()  # í˜„ì¬ datetime
        data = [(now, word) for word in keywords]
        self.cursor.executemany(query, data)
        self.conn.commit()
        print(f"âœ… {section.upper()} - ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì €ì¥ ì™„ë£Œ!")

    def fetch_keywords(self):
        """tb_newsKeyword í…Œì´ë¸”ì—ì„œ news_dateì™€ news_keywordë¥¼ í•¨ê»˜ ì¡°íšŒ"""
        query = "SELECT news_date, news_keyword FROM tb_newsKeyword"
        self.cursor.execute(query)
        result = self.cursor.fetchall()  # ê° row: (news_date, news_keyword)
        return result

    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        self.cursor.close()
        self.conn.close()

class TextProcessor:
    def __init__(self):
        """Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ê°ì²´ ìƒì„±"""
        self.okt = Okt()

    def KonlpyOkt(self, querys):
        """ë¬¸ì¥ì—ì„œ ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ (í•œ ê¸€ì ë‹¨ì–´ ì œê±°)"""
        result = []
        for query in querys:
            if isinstance(query, str):
                nouns = self.okt.nouns(query)
                filtered_noun = [word for word in nouns if len(word) > 1]
                if filtered_noun:
                    result.extend(filtered_noun)
        return result

def scrape_h2_text(url):
    """URLì—ì„œ <h2> íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤í¬ë˜í•‘"""
    try:
        response = requests.get(url)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"âŒ {url} ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    soup = BeautifulSoup(response.text, 'html.parser')
    h2_tags = soup.find_all('h2')
    return [tag.get_text(strip=True) for tag in h2_tags]

if __name__ == "__main__":
    sections = {
        "politics": [
            "https://www.joongang.co.kr/politics",
            "https://www.joongang.co.kr/politics?page=2",
            "https://www.joongang.co.kr/politics?page=3"
        ],
        "sports": [
            "https://www.joongang.co.kr/sports",
            "https://www.joongang.co.kr/sports?page=2",
            "https://www.joongang.co.kr/sports?page=3"
        ],
        "economic": [
            "https://www.joongang.co.kr/money",
            "https://www.joongang.co.kr/money?page=2",
            "https://www.joongang.co.kr/money?page=3"
        ],
        "society": [
            "https://www.joongang.co.kr/society",
            "https://www.joongang.co.kr/society?page=2",
            "https://www.joongang.co.kr/society?page=3"
        ],
        "world": [
            "https://www.joongang.co.kr/world",
            "https://www.joongang.co.kr/world?page=2",
            "https://www.joongang.co.kr/world?page=3"
        ],

    }

    processor = TextProcessor()
    db = MySQLDatabase()

    for section, urls in sections.items():
        all_nouns = []
        for url in urls:
            h2_texts = scrape_h2_text(url)
            result = processor.KonlpyOkt(h2_texts)
            all_nouns.extend(result)

        # ìƒìœ„ 10ê°œ ë‹¨ì–´ ì¶”ì¶œ
        word_counts = Counter(all_nouns)
        top_10_words = [word for word, _ in word_counts.most_common(10)]

        # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë¥¼ DBì— ì €ì¥ (í˜„ì¬ datetime í¬í•¨)
        db.insert_top_keywords(section, top_10_words)

        print(f"\nğŸŸ¢ ìŠ¤í¬ë˜í•‘í•œ ì „ì²´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ({section.upper()}):")
        print(all_nouns)
        print(f"\nğŸ”µ ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‹¨ì–´ TOP 10 ({section.upper()}):")
        for word in top_10_words:
            print(word)

    # DBì— ì €ì¥ëœ í‚¤ì›Œë“œì™€ ë‚ ì§œ ì¡°íšŒ
    fetched_data = db.fetch_keywords()
    print("\nğŸ“Œ DBì—ì„œ ê°€ì ¸ì˜¨ í‚¤ì›Œë“œ ë° ë‚ ì§œ:")
    for news_date, keyword in fetched_data:
        print(f"{news_date} - {keyword}")

    db.close()
